{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "\n",
    "In this CF method, I am exploring the model based CF method through matrix factorization. This will build predictions for user-item rankings \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T00:20:38.147979Z",
     "start_time": "2018-11-07T00:20:38.132363Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:11:02.883627Z",
     "start_time": "2018-11-06T11:11:02.875889Z"
    }
   },
   "outputs": [],
   "source": [
    "seed=5543\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:11:07.007184Z",
     "start_time": "2018-11-06T11:11:02.911627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>TimeStamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  TimeStamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameterize directory path \n",
    "raw_dir=\"../raw/ml-1m\"\n",
    "raw_file=\"/ratings.dat\"\n",
    "\n",
    "#In CF techniques, reading only the user-item interaction data: ratings\n",
    "filename=raw_dir+raw_file\n",
    "data_all=pd.read_csv(filename,sep=\"::\",header=None,names=[\"userId\",\"movieId\",\"rating\",\"TimeStamp\"])\n",
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension (1000209, 4)\n",
      "Unique Users 6040\n",
      "Unique Movie 3706\n",
      "Data Sparsity 4.47\n"
     ]
    }
   ],
   "source": [
    "#Quick Data Stats\n",
    "print(\"Dimension\",data_all.shape)\n",
    "print(\"Unique Users\",data_all['userId'].nunique())\n",
    "print(\"Unique Movie\",data_all['movieId'].nunique())\n",
    "print(\"Data Sparsity {0:.2f}\".format(len(data_all)*100/(data_all['userId'].nunique()*data_all['movieId'].nunique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "\n",
    "Note: Production product to treat new users/movies separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:11:07.030090Z",
     "start_time": "2018-11-06T11:11:07.022085Z"
    }
   },
   "outputs": [],
   "source": [
    "#Currently, the new users or new movies are asigned at random\n",
    "userEncoder=LabelEncoder()\n",
    "movieEncoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating arrays of users, movies and ratings\n",
    "users_all=userEncoder.fit_transform(data_all[[\"userId\"]].values.ravel())\n",
    "movies_all=movieEncoder.fit_transform(data_all[[\"movieId\"]].values.ravel())\n",
    "ratings_all=data_all[[\"rating\"]].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:11:07.356903Z",
     "start_time": "2018-11-06T11:11:07.213901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size 722650\n",
      "Validation Size 127527\n",
      "Test Size 150032\n"
     ]
    }
   ],
   "source": [
    "# Create train, validation & test datasets\n",
    "users,users_test,movies,movies_test,ratings, ratings_test=train_test_split(users_all,movies_all,ratings_all,test_size=0.15)\n",
    "users_train,users_val, movies_train,movies_val, ratings_train,ratings_val=train_test_split(users,movies,ratings,test_size=0.15)\n",
    "print(\"Training Size\", len(users_train))\n",
    "print(\"Validation Size\", len(users_val))\n",
    "print(\"Test Size\", len(users_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:11:07.489946Z",
     "start_time": "2018-11-06T11:11:07.481959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_users 6040\n",
      "N_movies 3706\n"
     ]
    }
   ],
   "source": [
    "#Create labeling and counts of unique users & movies\n",
    "unique_users=userEncoder.classes_\n",
    "unique_movies=movieEncoder.classes_\n",
    "\n",
    "N_users=len(unique_users) # all users\n",
    "N_movies=len(unique_movies) # all movies\n",
    "print(\"N_users\",N_users)\n",
    "print(\"N_movies\",N_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering\n",
    "analyzes relationships between users and\n",
    "interdependencies among products to\n",
    "identify new user-item associations.\n",
    "It's major appeal is that it is domain free, yet it can\n",
    "address data aspects that are often elusive\n",
    "and difficult to profile using content filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization\n",
    "\n",
    "\n",
    "A successful approach to the prediction of the ranking matrixri,uis basedon amatrix decompositionmodel, where our ranking predictions are:\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\hat{r}_{i,u} =\\mu + b_u + b_i + p_u^T q_i\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The model parameters θ= (μ,bu,bi,pu,qi) are defined as:\n",
    "\n",
    "*μ  Mean rating, its the average rating of all users over all movies in our trainingset\n",
    "bu User Bias, it will  be  higher  for  users  that  give  high average ratings to all movies\n",
    "bi Item Bias, it will be higher for the more popular (higherranked) movies\n",
    "pu User Embedding, a user F-dimensional vector that maps user u into some kind of abstract taste space\n",
    "qi Item Embedding, an item F-dimensional vector that maps itemsi into the taste space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Rating\n",
    "\n",
    "Mean rating over the training set is \n",
    "\t\\begin{equation}\n",
    "\t\t\t\\mu = \\frac{1}{N_\\mathcal{T}}\\sum_{(i,u)\\in\\mathcal{T}} r_{u,i}\n",
    "\t\t\\end{equation}\n",
    "And, we define the differential rating\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Delta r_{u,i} = r_{u,i} - \\mu\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:11:07.525948Z",
     "start_time": "2018-11-06T11:11:07.501949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall mean rating of training data: 3.58\n"
     ]
    }
   ],
   "source": [
    "# de-meaning the train ratings array\n",
    "mu=ratings_train.mean()\n",
    "drating=np.mean((ratings_train-mu)**2) \n",
    "print(\"overall mean rating of training data:\", round(mu,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Initialization\n",
    "\n",
    "We implement the following initialization\n",
    "\\begin{align}\n",
    "\tb_u^0  &\\sim \\mathcal{N}(0, 10^{-4}) \\\\\n",
    "\tb_i^0  &\\sim \\mathcal{N}(0, 10^{-4}) \\\\\n",
    "\tp_{u,f}^0  &\\sim \\mathcal{N}\\left(0, \\frac{1}{\\max({1},\\sqrt{F})}\\right) \\\\\n",
    "\tq_{i,f}^0  &\\sim \\mathcal{N}\\left(0, \\frac{1}{\\max({1},\\sqrt{F})}\\right) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:11:07.533954Z",
     "start_time": "2018-11-06T11:11:07.525948Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_params(F,N_users,N_movies):\n",
    "    b_users=np.random.normal(0,0.0001,N_users)\n",
    "    b_movies=np.random.normal(0,0.0001,N_movies)\n",
    "    p_users=np.random.normal(0,1/max(1,np.sqrt(F)),(N_users,F))\n",
    "    p_movies=np.random.normal(0,1//max(1,np.sqrt(F)),(N_movies,F))\n",
    "    return b_users,b_movies,p_users,p_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:11:07.545947Z",
     "start_time": "2018-11-06T11:11:07.533954Z"
    }
   },
   "outputs": [],
   "source": [
    "F=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:11:07.561950Z",
     "start_time": "2018-11-06T11:11:07.545947Z"
    }
   },
   "outputs": [],
   "source": [
    "#initializing params for the unique users and movies\n",
    "b_users,b_movies,p_users,p_movies=initialize_params(F,N_users,N_movies) \n",
    "params=[mu,b_users,b_movies,p_users,p_movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6040,), (3706,), (6040, 2), (3706, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_users.shape, b_movies.shape , p_users.shape , p_movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Model\n",
    "\n",
    "The model prediction for $r$ is given by\n",
    "\\begin{equation}\n",
    "\t\\hat{r}_{i,u} =\\mu + b_u + b_i + p_u^T q_i\n",
    "\\end{equation}\n",
    "\n",
    "The interaction dot  product pu*qi drives  users  and  items  pointing  in  nearly parallel directions in the latent space towards higher ratings. The  dimension F of  the  latent  space is  a  modelhyper-parameter that will be chosen by cross validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Popularity Model```\n",
    "In  the  special  case F=0,  where  there  is  no  interaction  term,  the relative ranking of items are the same for all users ru,i−ru,i′=bi−bi′ and we say that items are ranked by popularity.\n",
    "\n",
    "```Personalized Model```\n",
    "A recommender system that wishes to providepersonalized rankings instead of just suggesting the same items to all users needs an interaction term, because the preferences of each user for particular kinds of items is encoded exclusively on the interaction term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:12:10.880721Z",
     "start_time": "2018-11-06T11:12:10.865101Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_rating(users,movies,params):\n",
    "    mu,b_users,b_movies,p_users,p_movies=params \n",
    "    b_u=b_users[users] # is label encoding at work here? as the dim are of mismatch due to subsetting\n",
    "    b_m=b_movies[movies]\n",
    "    p_u=p_users[users]\n",
    "    p_m=p_movies[movies]\n",
    "    prod=np.sum(p_u*p_m,axis=1)\n",
    "    r_hat=mu+b_u+b_m+prod\n",
    "    return r_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:12:12.128333Z",
     "start_time": "2018-11-06T11:12:12.019116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.5811178 , 3.58137423, 3.58115786, 3.58146872, 3.58122582,\n",
       "       3.58112864, 3.58093923, 3.58123367, 3.58094814, 3.58119053])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R=predict_rating(users_train,movies_train,params)\n",
    "R[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric: MSE\n",
    "\n",
    "The error function is \n",
    "\\begin{equation}\n",
    "\tL(\\theta;\\{r\\}) = \\frac{1}{N_\\mathcal{S}} \\sum_{{u,i}\\in \\mathcal{S}} \\left( r_{u,i} - \\hat{r}_{u,i}\\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Assess performance using the mean square error between observed rankings ru,i and the predicted rankings ˆru,i\n",
    "\n",
    "For a test set S of observations (u,i) that have not been use during model training. NS is the number of elements of S, and θ is a vector of model parametersthat we will have to learn from the pairs (u,i) in the training set T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:12:31.650806Z",
     "start_time": "2018-11-06T11:12:31.635184Z"
    }
   },
   "outputs": [],
   "source": [
    "def rating_error(users,movies,rating,params0):\n",
    "    dr=rating-predict_rating(users,movies,params0)\n",
    "    return np.mean(dr**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:12:31.785660Z",
     "start_time": "2018-11-06T11:12:31.650806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.248742966734941"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_error(users_train,movies_train,ratings_train,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "N = 100\n",
    "for i1 in range(0,N,batch_size):\n",
    "    print(i1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "The loss function is \n",
    "\\begin{equation}\n",
    "\tL(\\ b_u,b_i,p_u,q_i;\\{r\\}) = \\frac{1}{N_\\mathcal{S}} \\sum_{{u,i}\\in \\mathcal{S}} \\left( r_{u,i} - \\hat{r}_{u,i}\\right)^2 + \\frac{λ}{2}(p_u^2 +p_q^2)\n",
    "\\end{equation}\n",
    "\n",
    "We can write the mean square error loss function expliclity in terms of the model parameters, including a regularization penalty λ\n",
    "\n",
    "\n",
    "where, for convenience, we have assumed no regularization penalty for the biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Step\n",
    "\n",
    "We will implement a step of stochastic gradient descent as:\n",
    "\\begin{equation}\n",
    "θ_{t+1}=θ_{t}−\\frac{γ∂L}{∂θ}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "We  can  learn  the  model  parametersθ=  (bu,bi,pu,qi)  by  gradient  descent. Assuming a learning rate γ we have\n",
    "\n",
    "\\begin{align}\n",
    "\tb_u & \\leftarrow  b_u +  \\gamma \\Delta r_{u,i} \\\\\n",
    "\tb_i &\\leftarrow b_i + \\gamma \\Delta r_{u,i} \\\\\n",
    "\tp_u & \\leftarrow p_u + \\gamma\\left(q_{i}\\Delta r_{u,i} - \\lambda p_u\\right) \\\\\n",
    "\tq_i &\\leftarrow q_i + \\gamma \\left(p_{u}\\Delta r_{u,i} - \\lambda q_u \\right)  \n",
    "\t\\label{eq:step}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:12:31.793660Z",
     "start_time": "2018-11-06T11:12:31.785660Z"
    }
   },
   "outputs": [],
   "source": [
    "def learning_step(user,movie,rating,parms0,penalty,batch_size, learning_rate):\n",
    "    N=len(rating)\n",
    "    mu,b_users,b_movies,p_users,p_movies=parms0\n",
    "    perm=np.random.permutation(len(rating)) # shuffling the order\n",
    "    for i1 in range(0,N,batch_size):\n",
    "        idx=perm[i1:i1+batch_size]  # defining the batches    \n",
    "        u=user[idx] # creating batches of user, movie & corresponding ratings\n",
    "        m=movie[idx]\n",
    "        r=rating[idx]\n",
    "        # running on batches\n",
    "        b_u=b_users[u] \n",
    "        b_m=b_movies[m]\n",
    "        p_u=p_users[u]\n",
    "        p_m=p_movies[m]\n",
    "        prod=np.sum(p_u*p_m,axis=1)\n",
    "        r_hat=mu+b_u+b_m+prod\n",
    "        dr=r-r_hat\n",
    "        # all parameters being updated for the batch \n",
    "        b_users[u] +=learning_rate*(dr) \n",
    "        b_movies[m]+=learning_rate*(dr) \n",
    "        p_users[u] +=learning_rate*(dr[:,np.newaxis]*p_m-penalty*p_u) \n",
    "        p_movies[m]+=learning_rate*(dr[:,np.newaxis]*p_u-penalty*p_m) \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function\n",
    "\n",
    "Given the hyperparameters we just train for a fixed number of epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:12:31.805660Z",
     "start_time": "2018-11-06T11:12:31.793660Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_ratings(users_train,movies_train,ratings_train,users_val,movies_val,ratings_val,\n",
    "                F,learning_rate,penalty,steps,batch_size):\n",
    "    \n",
    "    mu=ratings_train.mean()\n",
    "    b_users,b_movies,p_users,p_movies=initialize_params(F,N_users,N_movies)\n",
    "    parms=[mu,b_users,b_movies,p_users,p_movies]\n",
    "    for i1 in range(steps):  # for each iteration \n",
    "        # calculate loss\n",
    "        loss=rating_error(users_train,movies_train,ratings_train,parms)  \n",
    "        # calculate gradient : this step updates the param\n",
    "        learning_step(users_train,movies_train,ratings_train,parms,penalty,batch_size,learning_rate)\n",
    "        if i1 % (steps//10)==0:\n",
    "            val_loss=rating_error(users_val,movies_val,ratings_val,parms)\n",
    "            print(\"\\t\",i1,loss,val_loss)\n",
    "    loss=rating_error(users_train,movies_train,ratings_train,parms)\n",
    "    val_loss=rating_error(users_val,movies_val,ratings_val,parms)\n",
    "    print(\"\\tFinal\",loss,val_loss)\n",
    "    return val_loss,parms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:12:31.822476Z",
     "start_time": "2018-11-06T11:12:31.805660Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate=0.005\n",
    "penalty=0.1\n",
    "batch_size=50\n",
    "steps=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Popularity Model\n",
    "\n",
    "Here we asume the embedding spaceis not present $F=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:12:37.557124Z",
     "start_time": "2018-11-06T11:12:31.822476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 1.248746642725307 0.8909740526539852\n",
      "\t 1 0.8789293209282619 0.8551414073649105\n",
      "\t 2 0.8413121945710145 0.8422269447426097\n",
      "\t 3 0.827094512576697 0.8356778554860488\n",
      "\t 4 0.8199053667259332 0.831931600744101\n",
      "\t 5 0.8155451055453977 0.8298184162152527\n",
      "\t 6 0.8130133859324009 0.8284141083235405\n",
      "\t 7 0.8111815395205997 0.8274597323768608\n",
      "\t 8 0.8099879740889979 0.8269773267236272\n",
      "\t 9 0.8090191069252736 0.8264105330218547\n",
      "\tFinal 0.8081858378145389 0.8264105330218547\n"
     ]
    }
   ],
   "source": [
    "loss,params=fit_ratings(users_train,movies_train,ratings_train,\n",
    "            users_val,  movies_val, ratings_val,\n",
    "           0,learning_rate,penalty,10,batch_size\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model with interaction Term\n",
    "\n",
    "Here we asume the embedding space has dimension $F=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T11:15:16.533531Z",
     "start_time": "2018-11-06T11:12:37.557124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 1.2487413272977004 0.8919647278968952\n",
      "\t 20 0.8005053824001939 0.8255740981556862\n",
      "\t 40 0.7887831455433789 0.8150789791241544\n",
      "\t 60 0.758732024001011 0.7911134361845616\n",
      "\t 80 0.7444282606397932 0.781016275974047\n",
      "\t 100 0.737458723836546 0.7765548494867625\n",
      "\t 120 0.7336375008227668 0.7746195277755272\n",
      "\t 140 0.7312443829111536 0.7729298978347575\n",
      "\t 160 0.7299435936606753 0.7722617994295322\n",
      "\t 180 0.7288682180958788 0.7721030687230466\n",
      "\tFinal 0.7282453362354298 0.7719968017142065\n"
     ]
    }
   ],
   "source": [
    "loss,params=fit_ratings(users_train,movies_train,ratings_train,\n",
    "            users_val,  movies_val, ratings_val,\n",
    "           F,learning_rate,penalty,steps,batch_size\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colaborative Filter Model\n",
    "\n",
    "We graph the hyperparameters, training and prediction in a single model for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T12:09:23.745066Z",
     "start_time": "2018-11-06T12:09:23.729485Z"
    }
   },
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(self,F,penalty,learning_rate,steps,batch_size):\n",
    "        self.F=F\n",
    "        self.penalty=penalty\n",
    "        self.learning_rate=learning_rate\n",
    "        self.steps=steps\n",
    "        self.batch_size=batch_size\n",
    "    def fit(self,users,movies,ratings, users_val,movies_val,ratings_val):\n",
    "        print(self.learning_rate)\n",
    "        loss,params=fit_ratings(users,movies,ratings,\n",
    "                                users_val,movies_val,ratings_val,\n",
    "                                self.F,self.learning_rate,self.penalty,self.steps,self.batch_size\n",
    "                               )\n",
    "        self.params=params\n",
    "        return loss\n",
    "    def predict(users,movies):\n",
    "        return predict_ratings(users,movies,self.params)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T12:09:33.324999Z",
     "start_time": "2018-11-06T12:09:24.791299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "\t 0 1.2487469417709074 0.862490541990662\n",
      "\t 1 0.8372222075003591 0.8541518090455639\n",
      "\t 2 0.8289942646731444 0.841746795804403\n",
      "\t 3 0.8119672643828387 0.8255759124791926\n",
      "\t 4 0.7958220560133544 0.8199763143835254\n",
      "\t 5 0.7877187927183887 0.8161607958539047\n",
      "\t 6 0.7804145261714563 0.8133187552081782\n",
      "\t 7 0.7726392392335325 0.8091079521261225\n",
      "\t 8 0.764157733836076 0.806333153899414\n",
      "\t 9 0.7594965349311226 0.8055844535672791\n",
      "\tFinal 0.7554680341329729 0.8055844535672791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8055844535672791"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Recommender(F=5,penalty=0.1,learning_rate=0.05,steps=10,batch_size=50)\n",
    "\n",
    "model.fit(users_train,movies_train,ratings_train,users_val,movies_val,ratings_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Search\n",
    "\n",
    "We do a grid search using a single validation set to find the range of penalties and embedding dimension that seems to perform best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T16:24:38.004194Z",
     "start_time": "2018-11-06T12:09:33.324999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F 1, penalty 0 :\n",
      "0.005\n",
      "\t 0 2.2344801906517 0.959256220584027\n",
      "\t 20 0.8002396962671804 0.8312209200203222\n",
      "\t 40 0.7803912003181386 0.8140237061299194\n",
      "\t 60 0.7595285194941104 0.794964023337011\n",
      "\t 80 0.7492251876246103 0.7877851508586758\n",
      "\t 100 0.7443787589575674 0.7849951256437588\n",
      "\t 120 0.7419771298225459 0.7833840405070284\n",
      "\t 140 0.7405735156601039 0.7831632036380954\n",
      "\t 160 0.7397415128263173 0.7827135662563025\n",
      "\t 180 0.7393891671239669 0.7828090357866355\n",
      "\tFinal 0.7389985939702544 0.783025690314756\n",
      "\n",
      "==> 1,0,0.783025690314756 == best (1,0,0.783025690314756) =============\n",
      "\n",
      "F 1, penalty 0.01 :\n",
      "0.005\n",
      "\t 0 2.1727577648255756 0.9619170246177703\n",
      "\t 20 0.799817323624675 0.8314801540021648\n",
      "\t 40 0.7744193903725163 0.8087748595117703\n",
      "\t 60 0.7539163386299534 0.7913928340905486\n",
      "\t 80 0.745699449495427 0.7857732181669718\n",
      "\t 100 0.7423456279385277 0.7836465732214088\n",
      "\t 120 0.7406458363490719 0.7829601330529306\n",
      "\t 140 0.739913160501363 0.7825950475279763\n",
      "\t 160 0.7393758644733875 0.7824914394617295\n",
      "\t 180 0.7391145232808307 0.7824549477446708\n",
      "\tFinal 0.7389318797554232 0.782245544238934\n",
      "\n",
      "==> 1,0.01,0.782245544238934 == best (1,0.01,0.782245544238934) =============\n",
      "\n",
      "F 1, penalty 0.05 :\n",
      "0.005\n",
      "\t 0 2.22782484809295 0.9574337711360523\n",
      "\t 20 0.8005962557136769 0.8278206981601536\n",
      "\t 40 0.7737800021116257 0.8029472220193138\n",
      "\t 60 0.7545220847552973 0.7880649118102803\n",
      "\t 80 0.7481170767088017 0.7833761978112981\n",
      "\t 100 0.7455339775886537 0.7819883905873457\n",
      "\t 120 0.7442576801016596 0.7809895912657445\n",
      "\t 140 0.7436248226885452 0.781317028438232\n",
      "\t 160 0.7431868518175754 0.7814770646909693\n",
      "\t 180 0.7429131913011964 0.7812141809230433\n",
      "\tFinal 0.742930390117363 0.7811427311825417\n",
      "\n",
      "==> 1,0.05,0.7811427311825417 == best (1,0.05,0.7811427311825417) =============\n",
      "\n",
      "F 1, penalty 0.1 :\n",
      "0.005\n",
      "\t 0 2.2998879767337943 0.94865832341099\n",
      "\t 20 0.8025407847047654 0.8261643352135608\n",
      "\t 40 0.7978415230156602 0.8227100535402417\n",
      "\t 60 0.7731395943323447 0.8020090799392158\n",
      "\t 80 0.7616203585480775 0.7931273800713119\n",
      "\t 100 0.757436653827674 0.7901976553319168\n",
      "\t 120 0.7554967120682479 0.7886946687855962\n",
      "\t 140 0.7544093158520775 0.788018946042671\n",
      "\t 160 0.753881260337391 0.7876973149841446\n",
      "\t 180 0.753373444165929 0.7876832316507966\n",
      "\tFinal 0.7532556204923453 0.7874266493323656\n",
      "\n",
      "==> 1,0.1,0.7874266493323656 == best (1,0.05,0.7811427311825417) =============\n",
      "\n",
      "F 1, penalty 0.15 :\n",
      "0.005\n",
      "\t 0 2.3615084470017167 0.9455901424599326\n",
      "\t 20 0.8036378053056598 0.8257545660428939\n",
      "\t 40 0.8034816119344883 0.8255101117556468\n",
      "\t 60 0.8028246010369071 0.8250884732485614\n",
      "\t 80 0.7971088703345579 0.8193376387181124\n",
      "\t 100 0.7820339477547481 0.8070575807554973\n",
      "\t 120 0.7747926986060697 0.8020437437902818\n",
      "\t 140 0.7718151986260214 0.7999026477054596\n",
      "\t 160 0.7703846267486993 0.7989484806251388\n",
      "\t 180 0.7696930874801949 0.7984444857178105\n",
      "\tFinal 0.7691117483519625 0.798359654141318\n",
      "\n",
      "==> 1,0.15,0.798359654141318 == best (1,0.05,0.7811427311825417) =============\n",
      "\n",
      "F 1, penalty 0.2 :\n",
      "0.005\n",
      "\t 0 2.144718142351576 0.9382688490794812\n",
      "\t 20 0.8043563739819616 0.8255469159378354\n",
      "\t 40 0.8042134760344822 0.8251034545759575\n",
      "\t 60 0.8042335963989198 0.8253291584740836\n",
      "\t 80 0.8043280090901824 0.8251226034851642\n",
      "\t 100 0.8041588158193193 0.8249679164772292\n",
      "\t 120 0.8038930027779247 0.8246147063945938\n",
      "\t 140 0.8031872480850731 0.8243996167092941\n",
      "\t 160 0.8013573812809557 0.8230329899910507\n",
      "\t 180 0.7986677987396332 0.8205705688233156\n",
      "\tFinal 0.7954744124530394 0.8180558598500397\n",
      "\n",
      "==> 1,0.2,0.8180558598500397 == best (1,0.05,0.7811427311825417) =============\n",
      "\n",
      "F 1, penalty 1 :\n",
      "0.005\n",
      "\t 0 2.1850702700192235 0.9004920441194797\n",
      "\t 20 0.8056950921759777 0.8250026729990975\n",
      "\t 40 0.8051291053072704 0.8251188445986511\n",
      "\t 60 0.8047975619180274 0.8248877625979244\n",
      "\t 80 0.8047878608945274 0.8252056325800518\n",
      "\t 100 0.8047403388511186 0.8248653924794909\n",
      "\t 120 0.8046474760688916 0.8254524409424571\n",
      "\t 140 0.804647151589629 0.8255704338462324\n",
      "\t 160 0.8046613257338889 0.8253600963125327\n",
      "\t 180 0.804744690512457 0.8253723065718233\n",
      "\tFinal 0.8047057245623626 0.8253474250813881\n",
      "\n",
      "==> 1,1,0.8253474250813881 == best (1,0.05,0.7811427311825417) =============\n",
      "\n",
      "F 5, penalty 0 :\n",
      "0.005\n",
      "\t 0 1.2487519467851393 0.8914313172222713\n",
      "\t 20 0.7540348337754765 0.8188573975220883\n",
      "\t 40 0.6931681017602317 0.7856168904310806\n",
      "\t 60 0.6631137897215234 0.7707018371874148\n",
      "\t 80 0.6481467967042795 0.7656459186473105\n",
      "\t 100 0.6399518986891711 0.7643125710811943\n",
      "\t 120 0.6350261910879212 0.7647242282819391\n",
      "\t 140 0.6317579054395714 0.7656724352594662\n",
      "\t 160 0.6296152106956328 0.7670297351944269\n",
      "\t 180 0.6280132923869537 0.768385287559703\n",
      "\tFinal 0.6268685592874637 0.7691923779155934\n",
      "\n",
      "==> 5,0,0.7691923779155934 == best (5,0,0.7691923779155934) =============\n",
      "\n",
      "F 5, penalty 0.01 :\n",
      "0.005\n",
      "\t 0 1.2487424090636263 0.8914210149916304\n",
      "\t 20 0.7501904846820994 0.8100127762254218\n",
      "\t 40 0.6869697527820187 0.7752405110945721\n",
      "\t 60 0.658500652718174 0.7619057901237917\n",
      "\t 80 0.6445745310095291 0.756947528635432\n",
      "\t 100 0.6373481234984844 0.7554584331854132\n",
      "\t 120 0.6331310783867706 0.7553018118328889\n",
      "\t 140 0.6303427933775629 0.7559025231465992\n",
      "\t 160 0.6284158439081149 0.7560798263307074\n",
      "\t 180 0.6271881582010904 0.7566135839380402\n",
      "\tFinal 0.626121669997547 0.7568059503334624\n",
      "\n",
      "==> 5,0.01,0.7568059503334624 == best (5,0.01,0.7568059503334624) =============\n",
      "\n",
      "F 5, penalty 0.05 :\n",
      "0.005\n",
      "\t 0 1.2487417042961348 0.8911950147852824\n",
      "\t 20 0.758648120155929 0.8014269493526167\n",
      "\t 40 0.7002958423365978 0.766768827423283\n",
      "\t 60 0.6736068726576228 0.7532670511641145\n",
      "\t 80 0.6611575326662288 0.7477660323538962\n",
      "\t 100 0.6542682584282374 0.7443775300992092\n",
      "\t 120 0.6499392243019598 0.7429293311817046\n",
      "\t 140 0.6471116436590488 0.7419841862604785\n",
      "\t 160 0.6452221675763133 0.7416062316623222\n",
      "\t 180 0.6437976208050035 0.741060602138343\n",
      "\tFinal 0.6428675418166774 0.7408816741349329\n",
      "\n",
      "==> 5,0.05,0.7408816741349329 == best (5,0.05,0.7408816741349329) =============\n",
      "\n",
      "F 5, penalty 0.1 :\n",
      "0.005\n",
      "\t 0 1.2487452077689114 0.8911349076927657\n",
      "\t 20 0.7951239722632744 0.8228399200226031\n",
      "\t 40 0.7584170910815341 0.7930208088263241\n",
      "\t 60 0.7324160226453532 0.7763191127443158\n",
      "\t 80 0.7164219025581032 0.7672995099707601\n",
      "\t 100 0.7056968545618101 0.7619828522275498\n",
      "\t 120 0.6983470745459148 0.7584677460773968\n",
      "\t 140 0.693464710679723 0.7557460941280703\n",
      "\t 160 0.6905283979162348 0.7543174373526876\n",
      "\t 180 0.6882937486485109 0.7534287511094648\n",
      "\tFinal 0.686929195263307 0.7529442546072044\n",
      "\n",
      "==> 5,0.1,0.7529442546072044 == best (5,0.05,0.7408816741349329) =============\n",
      "\n",
      "F 5, penalty 0.15 :\n",
      "0.005\n",
      "\t 0 1.2487432397579634 0.8909945661829227\n",
      "\t 20 0.8021502928452856 0.824530261442237\n",
      "\t 40 0.7978965911229258 0.820735631768874\n",
      "\t 60 0.7800893693881693 0.8058268029840435\n",
      "\t 80 0.7693982840680209 0.7979976605610885\n",
      "\t 100 0.7637597218292618 0.7943822037299224\n",
      "\t 120 0.759760909982892 0.7918462529530663\n",
      "\t 140 0.7569514984254768 0.7899775511835269\n",
      "\t 160 0.7548024365650781 0.7892940014200737\n",
      "\t 180 0.7531529745892823 0.7882019593428191\n",
      "\tFinal 0.7516435615799198 0.7876518704392834\n",
      "\n",
      "==> 5,0.15,0.7876518704392834 == best (5,0.05,0.7408816741349329) =============\n",
      "\n",
      "F 5, penalty 0.2 :\n",
      "0.005\n",
      "\t 0 1.2487464558246577 0.890488445026727\n",
      "\t 20 0.8040837530099325 0.8248486078300077\n",
      "\t 40 0.8040193447478202 0.8246185082588493\n",
      "\t 60 0.8035491363951052 0.8246030906409635\n",
      "\t 80 0.8024395027372982 0.8236356649517357\n",
      "\t 100 0.8000631135498324 0.8215234948023252\n",
      "\t 120 0.7967198358286818 0.8187395000505601\n",
      "\t 140 0.793760739549958 0.8165898056026443\n",
      "\t 160 0.7916004293073322 0.8147873967436836\n",
      "\t 180 0.7901056869435714 0.8143525623806299\n",
      "\tFinal 0.7893830737898149 0.8138004799300811\n",
      "\n",
      "==> 5,0.2,0.8138004799300811 == best (5,0.05,0.7408816741349329) =============\n",
      "\n",
      "F 5, penalty 1 :\n",
      "0.005\n",
      "\t 0 1.2487457196886538 0.8903231717510978\n",
      "\t 20 0.8056982245772378 0.8251137550910778\n",
      "\t 40 0.8050336631265117 0.8248116184698633\n",
      "\t 60 0.8048819932031562 0.825542703240436\n",
      "\t 80 0.804875170767641 0.8250374229666965\n",
      "\t 100 0.804717003253785 0.8253142573508255\n",
      "\t 120 0.8047144230571159 0.8253242311327081\n",
      "\t 140 0.804593327766286 0.8252217330677083\n",
      "\t 160 0.8047492825783892 0.8255320467138784\n",
      "\t 180 0.8046737183203613 0.8255355327327403\n",
      "\tFinal 0.804713655475462 0.8250972584480364\n",
      "\n",
      "==> 5,1,0.8250972584480364 == best (5,0.05,0.7408816741349329) =============\n",
      "\n",
      "F 10, penalty 0 :\n",
      "0.005\n",
      "\t 0 1.2487458049875888 0.8910147669489128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 20 0.6946459172164565 0.8059196806693047\n",
      "\t 40 0.6178624498328793 0.7877722701764298\n",
      "\t 60 0.5851009917881986 0.785602886001359\n",
      "\t 80 0.5682867103908575 0.7880250157092928\n",
      "\t 100 0.5586461648801608 0.7910344514433932\n",
      "\t 120 0.5523904894296855 0.79515608307838\n",
      "\t 140 0.5481496991741914 0.7987258318116642\n",
      "\t 160 0.5451225068111829 0.8024894688294515\n",
      "\t 180 0.5427293886802181 0.8066435594603161\n",
      "\tFinal 0.5409430577934915 0.8098907319819626\n",
      "\n",
      "==> 10,0,0.8098907319819626 == best (5,0.05,0.7408816741349329) =============\n",
      "\n",
      "F 10, penalty 0.01 :\n",
      "0.005\n",
      "\t 0 1.2487413560250222 0.891063950697708\n",
      "\t 20 0.6950510096497438 0.7948938380044696\n",
      "\t 40 0.6146140700633023 0.7760206381607712\n",
      "\t 60 0.583601459746858 0.7734589120928691\n",
      "\t 80 0.5687043496305516 0.7748738339199879\n",
      "\t 100 0.560034358370441 0.7779814149876839\n",
      "\t 120 0.554586915595641 0.7804912043460952\n",
      "\t 140 0.550685478572145 0.7828372783959465\n",
      "\t 160 0.5478774390083434 0.7855160850725289\n",
      "\t 180 0.5456484844098666 0.7875930298983886\n",
      "\tFinal 0.5438713206257556 0.7895522686935582\n",
      "\n",
      "==> 10,0.01,0.7895522686935582 == best (5,0.05,0.7408816741349329) =============\n",
      "\n",
      "F 10, penalty 0.05 :\n",
      "0.005\n",
      "\t 0 1.2487444407401112 0.8911647939058714\n",
      "\t 20 0.7390334735068532 0.793940372558982\n",
      "\t 40 0.6596405036034756 0.7565230533408733\n",
      "\t 60 0.6239958788453067 0.7463305832187674\n",
      "\t 80 0.6061321879222565 0.7429778021938274\n",
      "\t 100 0.5957348142052806 0.7411497541586972\n",
      "\t 120 0.5890277814772503 0.7400908969420253\n",
      "\t 140 0.5845874226984382 0.7392402628495046\n",
      "\t 160 0.5814742119332366 0.7391163164555279\n",
      "\t 180 0.579192488704485 0.7389879146161726\n",
      "\tFinal 0.5772471953021207 0.7386847270140305\n",
      "\n",
      "==> 10,0.05,0.7386847270140305 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 10, penalty 0.1 :\n",
      "0.005\n",
      "\t 0 1.248751686633465 0.8910012231966338\n",
      "\t 20 0.7875272491876362 0.8164266552203241\n",
      "\t 40 0.7429387906110826 0.783440924405029\n",
      "\t 60 0.7149846501849791 0.7674453537300476\n",
      "\t 80 0.6975187524019599 0.7597206775517158\n",
      "\t 100 0.6853003929359361 0.7555115361617044\n",
      "\t 120 0.6766766082766565 0.752338384008676\n",
      "\t 140 0.670347967966702 0.75065213569991\n",
      "\t 160 0.6655396524339342 0.7491033297016496\n",
      "\t 180 0.6621377820194414 0.748601571773416\n",
      "\tFinal 0.6594028892085303 0.7476926768229368\n",
      "\n",
      "==> 10,0.1,0.7476926768229368 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 10, penalty 0.15 :\n",
      "0.005\n",
      "\t 0 1.2487458770323947 0.890621885670107\n",
      "\t 20 0.8006895640339117 0.8239311763423491\n",
      "\t 40 0.7888521996708738 0.8127699122011991\n",
      "\t 60 0.7746176403500585 0.8021175774440784\n",
      "\t 80 0.7685481079954135 0.798003110693475\n",
      "\t 100 0.7639949031351974 0.7950919458899334\n",
      "\t 120 0.759968328992778 0.7921190204972774\n",
      "\t 140 0.7567688719654474 0.7907332916785852\n",
      "\t 160 0.7541967082217645 0.789444806962998\n",
      "\t 180 0.7521306697449871 0.78819542385863\n",
      "\tFinal 0.7503078814988631 0.7873459124153354\n",
      "\n",
      "==> 10,0.15,0.7873459124153354 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 10, penalty 0.2 :\n",
      "0.005\n",
      "\t 0 1.248743673714015 0.890681303948237\n",
      "\t 20 0.803911128564715 0.8248867905005729\n",
      "\t 40 0.8039090198113891 0.8246996608623287\n",
      "\t 60 0.8033963256264521 0.8244709547986863\n",
      "\t 80 0.802312160892487 0.8231012476075844\n",
      "\t 100 0.7998812906040427 0.8214814285550368\n",
      "\t 120 0.7965108337693212 0.8187856708132797\n",
      "\t 140 0.7935041999292181 0.816500394844096\n",
      "\t 160 0.7914048876722936 0.8149503156078202\n",
      "\t 180 0.7901196067299026 0.8143603237616709\n",
      "\tFinal 0.7892749710917379 0.8136976345955566\n",
      "\n",
      "==> 10,0.2,0.8136976345955566 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 10, penalty 1 :\n",
      "0.005\n",
      "\t 0 1.2487448176836633 0.8906354113458224\n",
      "\t 20 0.8057866618304796 0.8249099426128892\n",
      "\t 40 0.8050792967576422 0.8248481234975948\n",
      "\t 60 0.8049588546564324 0.825533983033296\n",
      "\t 80 0.8048021710138349 0.8250312833711957\n",
      "\t 100 0.8047773875182943 0.8252583079952389\n",
      "\t 120 0.8046241374479437 0.8249589842260492\n",
      "\t 140 0.8046953842520203 0.825274137464625\n",
      "\t 160 0.804705855572875 0.8255104251527114\n",
      "\t 180 0.8045480531033323 0.8255422455543614\n",
      "\tFinal 0.8047009606609821 0.8252690214542806\n",
      "\n",
      "==> 10,1,0.8252690214542806 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 20, penalty 0 :\n",
      "0.005\n",
      "\t 0 1.24874789262575 0.8902805691343902\n",
      "\t 20 0.6220832071727034 0.811685060275586\n",
      "\t 40 0.5183775578905109 0.8307256425742571\n",
      "\t 60 0.47869145942301367 0.8544301118947626\n",
      "\t 80 0.45889035693068275 0.8752988413814952\n",
      "\t 100 0.44699734411028436 0.8938414050600648\n",
      "\t 120 0.4391561050854247 0.9101446529545145\n",
      "\t 140 0.4335746102948854 0.9245083295722268\n",
      "\t 160 0.4293348010935251 0.9381206681792761\n",
      "\t 180 0.4260201344760096 0.9498643124144066\n",
      "\tFinal 0.4233261951306424 0.9600259781264696\n",
      "\n",
      "==> 20,0,0.9600259781264696 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 20, penalty 0.01 :\n",
      "0.005\n",
      "\t 0 1.2487399512570634 0.8908540398360131\n",
      "\t 20 0.6326904124502285 0.7954675568592476\n",
      "\t 40 0.5242544052374695 0.8006422343129017\n",
      "\t 60 0.4840347654794178 0.8140959173352721\n",
      "\t 80 0.4641510796382011 0.8266883716376854\n",
      "\t 100 0.45241827499579035 0.8367485105112116\n",
      "\t 120 0.4447232358841531 0.8456838193372473\n",
      "\t 140 0.43921807417249586 0.8530054513015661\n",
      "\t 160 0.43504187389574817 0.8598883290014282\n",
      "\t 180 0.43186117461053625 0.8660715565732107\n",
      "\tFinal 0.42921779941958094 0.8710928551600683\n",
      "\n",
      "==> 20,0.01,0.8710928551600683 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 20, penalty 0.05 :\n",
      "0.005\n",
      "\t 0 1.248750058000167 0.8908805531380147\n",
      "\t 20 0.7080005286812889 0.7825125692703395\n",
      "\t 40 0.603838307702752 0.7495459765488482\n",
      "\t 60 0.5543262968043606 0.7442449951268506\n",
      "\t 80 0.5303317583573269 0.7442175363558894\n",
      "\t 100 0.5170087372923294 0.7454979241344682\n",
      "\t 120 0.5087387601801786 0.746254569110907\n",
      "\t 140 0.503182079882982 0.7475983198286903\n",
      "\t 160 0.4991148089506425 0.7485473208525907\n",
      "\t 180 0.49611413699589435 0.7492756077199867\n",
      "\tFinal 0.49388477527567276 0.7497196399808174\n",
      "\n",
      "==> 20,0.05,0.7497196399808174 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 20, penalty 0.1 :\n",
      "0.005\n",
      "\t 0 1.2487394880481166 0.8906596716062375\n",
      "\t 20 0.7795164020556296 0.8102287896808242\n",
      "\t 40 0.7349294880903361 0.7794382754035207\n",
      "\t 60 0.7038697717322893 0.7627772901759315\n",
      "\t 80 0.6826330470785087 0.7540067182749846\n",
      "\t 100 0.6682861858483985 0.7497546791645305\n",
      "\t 120 0.6578485323085907 0.7470591899851798\n",
      "\t 140 0.6500682892305109 0.7456319032971662\n",
      "\t 160 0.6439305501936956 0.7445496295037262\n",
      "\t 180 0.6391589435548457 0.7438329348176909\n",
      "\tFinal 0.6352953646233727 0.7433512645656882\n",
      "\n",
      "==> 20,0.1,0.7433512645656882 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 20, penalty 0.15 :\n",
      "0.005\n",
      "\t 0 1.2487458812496908 0.890144222513489\n",
      "\t 20 0.8003824649464009 0.8240452104925701\n",
      "\t 40 0.7877759512674375 0.8120277117912147\n",
      "\t 60 0.7728857591311644 0.8008028716959004\n",
      "\t 80 0.7658911830639452 0.7962137126283876\n",
      "\t 100 0.760746025495881 0.7928252130870965\n",
      "\t 120 0.7569167407164454 0.790665272010567\n",
      "\t 140 0.7541699059717213 0.789366838146999\n",
      "\t 160 0.7518026310531524 0.7883255888819773\n",
      "\t 180 0.7499602500011779 0.7871462587404293\n",
      "\tFinal 0.7485117870978418 0.786422223629019\n",
      "\n",
      "==> 20,0.15,0.786422223629019 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 20, penalty 0.2 :\n",
      "0.005\n",
      "\t 0 1.2487451314228992 0.8908937478744487\n",
      "\t 20 0.8038738348667586 0.8250348216695488\n",
      "\t 40 0.8040110326800994 0.8249368266219569\n",
      "\t 60 0.8035619539262775 0.8244902123651602\n",
      "\t 80 0.8025005450841224 0.8236262640001567\n",
      "\t 100 0.8000789226132666 0.8213561612046713\n",
      "\t 120 0.7968956240289453 0.8191573156343837\n",
      "\t 140 0.7937177552304924 0.8167076384956553\n",
      "\t 160 0.7916283379453741 0.8151262096872035\n",
      "\t 180 0.7901597772522579 0.8144162591985188\n",
      "\tFinal 0.7892795383980921 0.813762236837523\n",
      "\n",
      "==> 20,0.2,0.813762236837523 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 20, penalty 1 :\n",
      "0.005\n",
      "\t 0 1.248742138838537 0.8904451541578813\n",
      "\t 20 0.8058355313791783 0.8252286157542186\n",
      "\t 40 0.8050802035970481 0.8250318882723184\n",
      "\t 60 0.8049279198291346 0.8250917406622775\n",
      "\t 80 0.8047902493017333 0.8250559506578365\n",
      "\t 100 0.804732061584438 0.8252475235101449\n",
      "\t 120 0.8047698276890639 0.8250879751201734\n",
      "\t 140 0.8047428844668506 0.8253516945911916\n",
      "\t 160 0.8046602363570706 0.8251333676809698\n",
      "\t 180 0.8046462469546163 0.8254743022285164\n",
      "\tFinal 0.8046228414163363 0.8252113751680418\n",
      "\n",
      "==> 20,1,0.8252113751680418 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 30, penalty 0 :\n",
      "0.005\n",
      "\t 0 1.248742198131788 0.8908637575783465\n",
      "\t 20 0.5667912965801168 0.8254345984430046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 40 0.4428035244004919 0.8766881417649168\n",
      "\t 60 0.3981245577373359 0.9187884261731454\n",
      "\t 80 0.3759688516452823 0.9530717618113255\n",
      "\t 100 0.3626812795005577 0.9832192241437021\n",
      "\t 120 0.35373335097595715 1.0091397575345704\n",
      "\t 140 0.34719719761503803 1.0333565597768315\n",
      "\t 160 0.3422753898100813 1.0548251505823083\n",
      "\t 180 0.3383466906082895 1.074290908788388\n",
      "\tFinal 0.33514100322162094 1.0920977661389086\n",
      "\n",
      "==> 30,0,1.0920977661389086 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 30, penalty 0.01 :\n",
      "0.005\n",
      "\t 0 1.2487399806463462 0.8905193005811562\n",
      "\t 20 0.58305582096466 0.7943801435677353\n",
      "\t 40 0.4535569069469815 0.8225152134017165\n",
      "\t 60 0.40773785047171446 0.8504066700599652\n",
      "\t 80 0.38534176731043573 0.8724005904314591\n",
      "\t 100 0.37202087030725695 0.8892364430771884\n",
      "\t 120 0.3631411550199517 0.9037442831317904\n",
      "\t 140 0.35671681195685345 0.9150977350921367\n",
      "\t 160 0.35192093900623833 0.9252738651925596\n",
      "\t 180 0.34816515374816503 0.9339123262631603\n",
      "\tFinal 0.3450455189007698 0.9412031657122283\n",
      "\n",
      "==> 30,0.01,0.9412031657122283 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 30, penalty 0.05 :\n",
      "0.005\n",
      "\t 0 1.248746408122378 0.8905333583827507\n",
      "\t 20 0.6938307314072558 0.7757271282448381\n",
      "\t 40 0.5724800983210782 0.7441811105112264\n",
      "\t 60 0.5130277634137727 0.7425962962371758\n",
      "\t 80 0.48388017495737484 0.7454595730940007\n",
      "\t 100 0.4674300917442201 0.7477289098565852\n",
      "\t 120 0.4573319296352105 0.7501652899673534\n",
      "\t 140 0.45051128117774103 0.7518165257573525\n",
      "\t 160 0.4454003272153707 0.7527924308747928\n",
      "\t 180 0.44189661842887396 0.7539001811502191\n",
      "\tFinal 0.439013090027328 0.754643148640652\n",
      "\n",
      "==> 30,0.05,0.754643148640652 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 30, penalty 0.1 :\n",
      "0.005\n",
      "\t 0 1.2487436539420356 0.8904495322419136\n",
      "\t 20 0.7733846515077686 0.8057211964443026\n",
      "\t 40 0.7267339942578402 0.7752050565489299\n",
      "\t 60 0.6967535567361822 0.760514261793507\n",
      "\t 80 0.675485113911819 0.7529590600728522\n",
      "\t 100 0.6597634772680298 0.7488988409925732\n",
      "\t 120 0.6480236930254671 0.7460755835303395\n",
      "\t 140 0.6391672727954947 0.7446272956276054\n",
      "\t 160 0.6322593060688002 0.7439853091467004\n",
      "\t 180 0.626702227860188 0.74337197195178\n",
      "\tFinal 0.6225470572561415 0.7431977650415774\n",
      "\n",
      "==> 30,0.1,0.7431977650415774 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 30, penalty 0.15 :\n",
      "0.005\n",
      "\t 0 1.2487437286307987 0.8902928534538099\n",
      "\t 20 0.7999054354679345 0.8232704598507606\n",
      "\t 40 0.7859581269461026 0.8108544511953443\n",
      "\t 60 0.7723433014191545 0.80053529587185\n",
      "\t 80 0.7657157536806142 0.7959710193091999\n",
      "\t 100 0.7608361470805977 0.7930520758697779\n",
      "\t 120 0.7570155223238794 0.7908220101041699\n",
      "\t 140 0.7542718325955879 0.789090875663691\n",
      "\t 160 0.7520473276900411 0.7877053913556203\n",
      "\t 180 0.7501519464854026 0.7870892909713076\n",
      "\tFinal 0.7487549903146833 0.7861419402062926\n",
      "\n",
      "==> 30,0.15,0.7861419402062926 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 30, penalty 0.2 :\n",
      "0.005\n",
      "\t 0 1.248738483644251 0.8901627410250016\n",
      "\t 20 0.8037517670223818 0.8248538841243241\n",
      "\t 40 0.8038835710352338 0.8250370323311369\n",
      "\t 60 0.8034530244717661 0.8241271984633588\n",
      "\t 80 0.8022735324635064 0.823495036457271\n",
      "\t 100 0.7998445395634948 0.8215660921326112\n",
      "\t 120 0.7965127134427722 0.8186754113952228\n",
      "\t 140 0.7934604359116051 0.8163985644375996\n",
      "\t 160 0.7914090614091904 0.8153228800353846\n",
      "\t 180 0.7901450758382341 0.8141155274667118\n",
      "\tFinal 0.789236163709932 0.8134120146891912\n",
      "\n",
      "==> 30,0.2,0.8134120146891912 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 30, penalty 1 :\n",
      "0.005\n",
      "\t 0 1.2487447397707212 0.8903486218780181\n",
      "\t 20 0.8056962097328852 0.8247586554439036\n",
      "\t 40 0.8051176804986591 0.8249613205503432\n",
      "\t 60 0.8048814738174304 0.8251401709067506\n",
      "\t 80 0.8048133664933651 0.8255022825847921\n",
      "\t 100 0.8047851421351362 0.8253363142255924\n",
      "\t 120 0.8047419180256971 0.8252204166207496\n",
      "\t 140 0.8047642711425382 0.8252249612568384\n",
      "\t 160 0.8046642364816612 0.8255441331733987\n",
      "\t 180 0.8046244460157392 0.8253239535739381\n",
      "\tFinal 0.8046145351986254 0.8254283698108238\n",
      "\n",
      "==> 30,1,0.8254283698108238 == best (10,0.05,0.7386847270140305) =============\n",
      "\n",
      "F 50, penalty 0 :\n",
      "0.005\n",
      "\t 0 1.2487444511981092 0.8903929792690466\n",
      "\t 20 0.48562822434217096 0.8361901292923792\n",
      "\t 40 0.3337080444547711 0.9442855371391127\n",
      "\t 60 0.2818858843776479 1.0218735194165125\n",
      "\t 80 0.256851085937325 1.081681394432843\n",
      "\t 100 0.2420152276456094 1.1313484493141872\n",
      "\t 120 0.23209967194542344 1.1750011910181513\n",
      "\t 140 0.22490990310261885 1.2135796993188077\n",
      "\t 160 0.21940091012012522 1.249529457252195\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "best_loss=1e10\n",
    "best_F=None\n",
    "best_penalty=None\n",
    "\n",
    "if True:\n",
    " for F in [1,5,10,20,30,50,100,150]:\n",
    "    for penalty in [0,0.01,0.05,0.1,0.15,0.2,1]:\n",
    "        print()\n",
    "        print(f\"F {F}, penalty {penalty} :\")\n",
    "        model=Recommender(F,penalty,learning_rate,steps,batch_size)\n",
    "        loss=model.fit(users_train,movies_train,ratings_train,\n",
    "                               users_val,movies_val,ratings_val)\n",
    "        results.append((F,penalty,loss))\n",
    "        if loss<best_loss:\n",
    "            best_loss=loss\n",
    "            best_F=F\n",
    "            best_penalty=penalty\n",
    "        print()\n",
    "        print(f\"==> {F},{penalty},{loss} == best ({best_F},{best_penalty},{best_loss}) =============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T16:24:38.016194Z",
     "start_time": "2018-11-06T16:24:38.004194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>penalty</th>\n",
       "      <th>val_rms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.782696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.782128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.781258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.787065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.798355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F  penalty   val_rms\n",
       "0  1     0.00  0.782696\n",
       "1  1     0.01  0.782128\n",
       "2  1     0.05  0.781258\n",
       "3  1     0.10  0.787065\n",
       "4  1     0.15  0.798355"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fits=pd.DataFrame(results,columns=[\"F\",\"penalty\",\"val_rms\"])\n",
    "fits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T16:24:38.048196Z",
     "start_time": "2018-11-06T16:24:38.016194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>penalty</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.15</th>\n",
       "      <th>0.2</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.782696</td>\n",
       "      <td>0.782128</td>\n",
       "      <td>0.781258</td>\n",
       "      <td>0.787065</td>\n",
       "      <td>0.798355</td>\n",
       "      <td>0.815372</td>\n",
       "      <td>0.825193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.764203</td>\n",
       "      <td>0.758633</td>\n",
       "      <td>0.741395</td>\n",
       "      <td>0.754068</td>\n",
       "      <td>0.788218</td>\n",
       "      <td>0.813963</td>\n",
       "      <td>0.825245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.813056</td>\n",
       "      <td>0.787762</td>\n",
       "      <td>0.737906</td>\n",
       "      <td>0.747374</td>\n",
       "      <td>0.786918</td>\n",
       "      <td>0.813867</td>\n",
       "      <td>0.825278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.952808</td>\n",
       "      <td>0.870673</td>\n",
       "      <td>0.749341</td>\n",
       "      <td>0.744736</td>\n",
       "      <td>0.787138</td>\n",
       "      <td>0.813556</td>\n",
       "      <td>0.825290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.083229</td>\n",
       "      <td>0.935764</td>\n",
       "      <td>0.754461</td>\n",
       "      <td>0.742779</td>\n",
       "      <td>0.786446</td>\n",
       "      <td>0.813682</td>\n",
       "      <td>0.825612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.302623</td>\n",
       "      <td>1.032195</td>\n",
       "      <td>0.754754</td>\n",
       "      <td>0.741674</td>\n",
       "      <td>0.786159</td>\n",
       "      <td>0.813525</td>\n",
       "      <td>0.825358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.582101</td>\n",
       "      <td>1.053754</td>\n",
       "      <td>0.748517</td>\n",
       "      <td>0.741486</td>\n",
       "      <td>0.786485</td>\n",
       "      <td>0.813546</td>\n",
       "      <td>0.825746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.522999</td>\n",
       "      <td>0.979739</td>\n",
       "      <td>0.738657</td>\n",
       "      <td>0.741149</td>\n",
       "      <td>0.786583</td>\n",
       "      <td>0.813672</td>\n",
       "      <td>0.825255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "penalty      0.00      0.01      0.05      0.10      0.15      0.20      1.00\n",
       "F                                                                            \n",
       "1        0.782696  0.782128  0.781258  0.787065  0.798355  0.815372  0.825193\n",
       "5        0.764203  0.758633  0.741395  0.754068  0.788218  0.813963  0.825245\n",
       "10       0.813056  0.787762  0.737906  0.747374  0.786918  0.813867  0.825278\n",
       "20       0.952808  0.870673  0.749341  0.744736  0.787138  0.813556  0.825290\n",
       "30       1.083229  0.935764  0.754461  0.742779  0.786446  0.813682  0.825612\n",
       "50       1.302623  1.032195  0.754754  0.741674  0.786159  0.813525  0.825358\n",
       "100      1.582101  1.053754  0.748517  0.741486  0.786485  0.813546  0.825746\n",
       "150      1.522999  0.979739  0.738657  0.741149  0.786583  0.813672  0.825255"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary=pd.pivot_table(fits,index=\"F\",columns=\"penalty\",values=\"val_rms\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T16:24:38.056194Z",
     "start_time": "2018-11-06T16:24:38.048196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F          10.000000\n",
       "penalty     0.050000\n",
       "val_rms     0.737906\n",
       "Name: 16, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best=fits.iloc[fits[\"val_rms\"].idxmin()]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T16:24:39.750218Z",
     "start_time": "2018-11-06T16:24:38.056194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row2_col2 {\n",
       "            background-color:  yellow;\n",
       "        }</style>  \n",
       "<table id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"index_name level0\" >penalty</th> \n",
       "        <th class=\"col_heading level0 col0\" >0.0</th> \n",
       "        <th class=\"col_heading level0 col1\" >0.01</th> \n",
       "        <th class=\"col_heading level0 col2\" >0.05</th> \n",
       "        <th class=\"col_heading level0 col3\" >0.1</th> \n",
       "        <th class=\"col_heading level0 col4\" >0.15</th> \n",
       "        <th class=\"col_heading level0 col5\" >0.2</th> \n",
       "        <th class=\"col_heading level0 col6\" >1.0</th> \n",
       "    </tr>    <tr> \n",
       "        <th class=\"index_name level0\" >F</th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724level0_row0\" class=\"row_heading level0 row0\" >1</th> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row0_col0\" class=\"data row0 col0\" >0.782696</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row0_col1\" class=\"data row0 col1\" >0.782128</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row0_col2\" class=\"data row0 col2\" >0.781258</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row0_col3\" class=\"data row0 col3\" >0.787065</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row0_col4\" class=\"data row0 col4\" >0.798355</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row0_col5\" class=\"data row0 col5\" >0.815372</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row0_col6\" class=\"data row0 col6\" >0.825193</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724level0_row1\" class=\"row_heading level0 row1\" >5</th> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row1_col0\" class=\"data row1 col0\" >0.764203</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row1_col1\" class=\"data row1 col1\" >0.758633</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row1_col2\" class=\"data row1 col2\" >0.741395</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row1_col3\" class=\"data row1 col3\" >0.754068</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row1_col4\" class=\"data row1 col4\" >0.788218</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row1_col5\" class=\"data row1 col5\" >0.813963</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row1_col6\" class=\"data row1 col6\" >0.825245</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724level0_row2\" class=\"row_heading level0 row2\" >10</th> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row2_col0\" class=\"data row2 col0\" >0.813056</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row2_col1\" class=\"data row2 col1\" >0.787762</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row2_col2\" class=\"data row2 col2\" >0.737906</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row2_col3\" class=\"data row2 col3\" >0.747374</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row2_col4\" class=\"data row2 col4\" >0.786918</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row2_col5\" class=\"data row2 col5\" >0.813867</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row2_col6\" class=\"data row2 col6\" >0.825278</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724level0_row3\" class=\"row_heading level0 row3\" >20</th> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row3_col0\" class=\"data row3 col0\" >0.952808</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row3_col1\" class=\"data row3 col1\" >0.870673</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row3_col2\" class=\"data row3 col2\" >0.749341</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row3_col3\" class=\"data row3 col3\" >0.744736</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row3_col4\" class=\"data row3 col4\" >0.787138</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row3_col5\" class=\"data row3 col5\" >0.813556</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row3_col6\" class=\"data row3 col6\" >0.82529</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724level0_row4\" class=\"row_heading level0 row4\" >30</th> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row4_col0\" class=\"data row4 col0\" >1.08323</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row4_col1\" class=\"data row4 col1\" >0.935764</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row4_col2\" class=\"data row4 col2\" >0.754461</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row4_col3\" class=\"data row4 col3\" >0.742779</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row4_col4\" class=\"data row4 col4\" >0.786446</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row4_col5\" class=\"data row4 col5\" >0.813682</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row4_col6\" class=\"data row4 col6\" >0.825612</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724level0_row5\" class=\"row_heading level0 row5\" >50</th> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row5_col0\" class=\"data row5 col0\" >1.30262</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row5_col1\" class=\"data row5 col1\" >1.0322</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row5_col2\" class=\"data row5 col2\" >0.754754</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row5_col3\" class=\"data row5 col3\" >0.741674</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row5_col4\" class=\"data row5 col4\" >0.786159</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row5_col5\" class=\"data row5 col5\" >0.813525</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row5_col6\" class=\"data row5 col6\" >0.825358</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724level0_row6\" class=\"row_heading level0 row6\" >100</th> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row6_col0\" class=\"data row6 col0\" >1.5821</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row6_col1\" class=\"data row6 col1\" >1.05375</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row6_col2\" class=\"data row6 col2\" >0.748517</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row6_col3\" class=\"data row6 col3\" >0.741486</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row6_col4\" class=\"data row6 col4\" >0.786485</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row6_col5\" class=\"data row6 col5\" >0.813546</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row6_col6\" class=\"data row6 col6\" >0.825746</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724level0_row7\" class=\"row_heading level0 row7\" >150</th> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row7_col0\" class=\"data row7 col0\" >1.523</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row7_col1\" class=\"data row7 col1\" >0.979739</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row7_col2\" class=\"data row7 col2\" >0.738657</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row7_col3\" class=\"data row7 col3\" >0.741149</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row7_col4\" class=\"data row7 col4\" >0.786583</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row7_col5\" class=\"data row7 col5\" >0.813672</td> \n",
       "        <td id=\"T_75a360fa_e1e0_11e8_8ebc_28c63f91b724row7_col6\" class=\"data row7 col6\" >0.825255</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24202a27630>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = sns.light_palette(\"#60FF60\", reverse=True, as_cmap=True)\n",
    "s = summary.style.highlight_min(axis=None)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T16:24:39.758217Z",
     "start_time": "2018-11-06T16:24:39.750218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 0.05)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_best=int(best[\"F\"])\n",
    "penalty_best=best[\"penalty\"]\n",
    "F_best,penalty_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "It seems $F\\approx 10$ with penalty around 0.05 gives best results.\n",
    "\n",
    "We use 5-Fold cross validation to find the optimal value of $F$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T16:24:39.842217Z",
     "start_time": "2018-11-06T16:24:39.758217Z"
    }
   },
   "outputs": [],
   "source": [
    "K=5\n",
    "kfold=KFold(K,shuffle=True)\n",
    "folds=[]\n",
    "for fold in kfold.split(users):\n",
    "    folds.append(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T16:24:39.850264Z",
     "start_time": "2018-11-06T16:24:39.842217Z"
    }
   },
   "outputs": [],
   "source": [
    "def ratings_cross_validate(model,users,movies,ratings,folds):\n",
    "    accuracies=[]\n",
    "    count=0\n",
    "    for train,val in folds:\n",
    "        print()\n",
    "        print(\"============= Fold\",count+1,\"===========\")\n",
    "        users_train=users[train]\n",
    "        movies_train=movies[train]\n",
    "        ratings_train=ratings[train]\n",
    "        users_val=users[val]\n",
    "        movies_val=movies[val]\n",
    "        ratings_val=ratings[val]\n",
    "        loss=model.fit(users_train,movies_train,ratings_train,\n",
    "                                   users_val,movies_val,ratings_val)\n",
    "        \n",
    "        accuracies.append(loss)\n",
    "        print(\"======= fold\",count+1,\"loss\",loss,\"============\")\n",
    "        print()\n",
    "        count+=1\n",
    "    accuracies=np.array(accuracies)\n",
    "    return accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T00:50:22.791082Z",
     "start_time": "2018-11-07T00:29:28.088213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F 5 :\n",
      "\n",
      "============= Fold 1 ===========\n",
      "\t 0 1.2485533530336144 0.8932260820557525\n",
      "\t 10 0.792153645151391 0.8284441461561335\n",
      "\t 20 0.7596851350083867 0.8073201016757684\n",
      "\t 30 0.7291479115139694 0.7905257533022896\n",
      "\t 40 0.7057719194647919 0.7788425942450067\n",
      "\t 50 0.6892993059143258 0.7706883615736058\n",
      "\t 60 0.6777306704150264 0.7652558488252055\n",
      "\t 70 0.6692703522347676 0.7611975269798796\n",
      "\t 80 0.6627616923298618 0.7585839984881941\n",
      "\t 90 0.6580722714403028 0.7560365320775337\n",
      "\tFinal 0.6544426100756603 0.754407832790789\n",
      "======= fold 1 loss 0.754407832790789 ============\n",
      "\n",
      "\n",
      "============= Fold 2 ===========\n",
      "\t 0 1.2478524832474827 0.8962957102144979\n",
      "\t 10 0.7922599406899052 0.8333267782960897\n",
      "\t 20 0.7670963705646401 0.8174016801086219\n",
      "\t 30 0.7343180194957236 0.7978551599139871\n",
      "\t 40 0.7100195764880174 0.7845717707513513\n",
      "\t 50 0.6914439061011414 0.7748161832518049\n",
      "\t 60 0.6778810060704996 0.7676659654676805\n",
      "\t 70 0.6686360374904579 0.763427531750924\n",
      "\t 80 0.6619130533879918 0.760341507843067\n",
      "\t 90 0.6572000510507808 0.758578890886326\n",
      "\tFinal 0.6536456243057528 0.757479807183501\n",
      "======= fold 2 loss 0.757479807183501 ============\n",
      "\n",
      "\n",
      "============= Fold 3 ===========\n",
      "\t 0 1.2492642792078534 0.8947221627768374\n",
      "\t 10 0.7939660288211087 0.8291699805414388\n",
      "\t 20 0.7698291012192804 0.8140464893229006\n",
      "\t 30 0.7347453025168861 0.7937635771912516\n",
      "\t 40 0.7106236713523204 0.7813324798833032\n",
      "\t 50 0.6920773171208617 0.7719964589021929\n",
      "\t 60 0.6783148439958833 0.7642082866316559\n",
      "\t 70 0.6685869790970365 0.7587455389347139\n",
      "\t 80 0.6615956323960517 0.7553360382804399\n",
      "\t 90 0.6566176963256017 0.7525007769328004\n",
      "\tFinal 0.6527355226218186 0.7508569211509154\n",
      "======= fold 3 loss 0.7508569211509154 ============\n",
      "\n",
      "\n",
      "============= Fold 4 ===========\n",
      "\t 0 1.2489324870318703 0.8903585678047412\n",
      "\t 10 0.7933966262071291 0.8287365536436028\n",
      "\t 20 0.766461055292232 0.8112898690569719\n",
      "\t 30 0.7309153312565705 0.7902043186630511\n",
      "\t 40 0.7045407033718348 0.7760313864894874\n",
      "\t 50 0.6858201256416288 0.7659844730188429\n",
      "\t 60 0.6732484689740458 0.7599294383376045\n",
      "\t 70 0.6649835345409911 0.7562610060662138\n",
      "\t 80 0.6591863975633268 0.7535902453687865\n",
      "\t 90 0.6550099862457914 0.7521867572408737\n",
      "\tFinal 0.6519220329742245 0.7515161240344423\n",
      "======= fold 4 loss 0.7515161240344423 ============\n",
      "\n",
      "\n",
      "============= Fold 5 ===========\n",
      "\t 0 1.2490152427609635 0.893431505158139\n",
      "\t 10 0.7911625996998342 0.8283252611915974\n",
      "\t 20 0.757712093784779 0.8059846045260528\n",
      "\t 30 0.725557802144149 0.7883267681958123\n",
      "\t 40 0.703368137343983 0.7778191151003601\n",
      "\t 50 0.6877735046280563 0.7705311388024559\n",
      "\t 60 0.6768508296167418 0.7661292627484646\n",
      "\t 70 0.6692222443367375 0.7629228794068688\n",
      "\t 80 0.663647100747699 0.7607534575750667\n",
      "\t 90 0.6593872115520141 0.7592617367194755\n",
      "\tFinal 0.6561867683883623 0.7583666675663374\n",
      "======= fold 5 loss 0.7583666675663374 ============\n",
      "\n",
      "\n",
      "==> 5,1,0.754525470545197 == best (5,0.05,0.754525470545197) =============\n",
      "\n",
      "F 10 :\n",
      "\n",
      "============= Fold 1 ===========\n",
      "\t 0 1.2485507126207753 0.8926275435426806\n",
      "\t 10 0.7862761820062014 0.8274531230444889\n",
      "\t 20 0.7421554213612975 0.8011269975382794\n",
      "\t 30 0.6926648920182926 0.7775103895572776\n",
      "\t 40 0.658036635543289 0.7641476629029821\n",
      "\t 50 0.6349463185082386 0.7570958604814425\n",
      "\t 60 0.6190352916259858 0.7529427190356769\n",
      "\t 70 0.608055937810148 0.7507933399951927\n",
      "\t 80 0.5999341315855167 0.7489396281767169\n",
      "\t 90 0.59379651970139 0.7479761752063447\n",
      "\tFinal 0.5890279745653612 0.7475656630691063\n",
      "======= fold 1 loss 0.7475656630691063 ============\n",
      "\n",
      "\n",
      "============= Fold 2 ===========\n",
      "\t 0 1.247859104552973 0.8957204059612365\n",
      "\t 10 0.7835047094072967 0.8300078580805131\n",
      "\t 20 0.7368639330843747 0.8022487223291547\n",
      "\t 30 0.6913535941334927 0.7809578633283307\n",
      "\t 40 0.6585717706643361 0.7693227383477997\n",
      "\t 50 0.6359333672085833 0.7626983160485273\n",
      "\t 60 0.620332734651667 0.7591373276489335\n",
      "\t 70 0.6090306037263348 0.7569080471475368\n",
      "\t 80 0.600838796425524 0.7549008998532963\n",
      "\t 90 0.594704880180038 0.7538008933434049\n",
      "\tFinal 0.5900114533459271 0.7534480009554136\n",
      "======= fold 2 loss 0.7534480009554136 ============\n",
      "\n",
      "\n",
      "============= Fold 3 ===========\n",
      "\t 0 1.2492654888087298 0.8938737991331048\n",
      "\t 10 0.7852745813360785 0.8267488383141236\n",
      "\t 20 0.7382178205568025 0.7984797417672413\n",
      "\t 30 0.6909847923764343 0.7755382680654787\n",
      "\t 40 0.6591106994161106 0.7636763214892184\n",
      "\t 50 0.6374818819110074 0.7575570871776217\n",
      "\t 60 0.6224177350065527 0.7539450368942835\n",
      "\t 70 0.6115390408582173 0.7519095881552704\n",
      "\t 80 0.6035215644256942 0.7505754032023687\n",
      "\t 90 0.5973769296684757 0.7496890075093582\n",
      "\tFinal 0.5923796101451001 0.7491827172114203\n",
      "======= fold 3 loss 0.7491827172114203 ============\n",
      "\n",
      "\n",
      "============= Fold 4 ===========\n",
      "\t 0 1.248936544942687 0.8903058664698152\n",
      "\t 10 0.7850506541023992 0.8262847549798703\n",
      "\t 20 0.7390474615951647 0.7993596841222609\n",
      "\t 30 0.6932186936680107 0.7777196918042024\n",
      "\t 40 0.6604324942233092 0.765194332541127\n",
      "\t 50 0.6381717546979699 0.7580062311169431\n",
      "\t 60 0.6227216234316897 0.7537959638808839\n",
      "\t 70 0.6115794888948204 0.7510828998414056\n",
      "\t 80 0.6031157790500361 0.748859279382836\n",
      "\t 90 0.5967498465396862 0.7476650481571516\n",
      "\tFinal 0.5917872397331728 0.7466662162395968\n",
      "======= fold 4 loss 0.7466662162395968 ============\n",
      "\n",
      "\n",
      "============= Fold 5 ===========\n",
      "\t 0 1.2490140597280115 0.8931897383396855\n",
      "\t 10 0.7837105675188053 0.8262348291113716\n",
      "\t 20 0.7358247698063187 0.7975254047240382\n",
      "\t 30 0.6911313857006126 0.7758901501841615\n",
      "\t 40 0.6585728774282388 0.7643239392454375\n",
      "\t 50 0.6366861615666882 0.7583383206830782\n",
      "\t 60 0.621596387247434 0.7550149550998296\n",
      "\t 70 0.6108668027072055 0.7529202861829065\n",
      "\t 80 0.6029439490513187 0.751850403982129\n",
      "\t 90 0.5969434520571604 0.7508717602564913\n",
      "\tFinal 0.5922324822973674 0.7508126736507373\n",
      "======= fold 5 loss 0.7508126736507373 ============\n",
      "\n",
      "\n",
      "==> 10,1,0.7495350542252549 == best (10,0.05,0.7495350542252549) =============\n",
      "\n",
      "F 15 :\n",
      "\n",
      "============= Fold 1 ===========\n",
      "\t 0 1.248555026495998 0.8925883572949387\n",
      "\t 10 0.7815127487605379 0.8267788375855819\n",
      "\t 20 0.7257008355739724 0.7963911772377493\n",
      "\t 30 0.6672511432483502 0.7719355035015518\n",
      "\t 40 0.6267449000803704 0.7605881901867618\n",
      "\t 50 0.5997348506521214 0.7554991022737152\n",
      "\t 60 0.5813603039725534 0.7530228253597514\n",
      "\t 70 0.5684495635173628 0.7520492121647997\n",
      "\t 80 0.5587691789585074 0.751436515578365\n",
      "\t 90 0.5515788259218983 0.7512336588572562\n",
      "\tFinal 0.5459469217516615 0.75120698218398\n",
      "======= fold 1 loss 0.75120698218398 ============\n",
      "\n",
      "\n",
      "============= Fold 2 ===========\n",
      "\t 0 1.247859609387365 0.8950559853872531\n",
      "\t 10 0.7789776413661729 0.8276392457243463\n",
      "\t 20 0.7211774614177043 0.7953988421237478\n",
      "\t 30 0.6676559502112225 0.7737830441714737\n",
      "\t 40 0.6281137586884737 0.7630338601117512\n",
      "\t 50 0.6006656381836355 0.7577160515948923\n",
      "\t 60 0.5819282025247141 0.75551378961243\n",
      "\t 70 0.5688281145154873 0.7543128485519889\n",
      "\t 80 0.5592884342776663 0.7539446696917186\n",
      "\t 90 0.55196446987085 0.7537506121110705\n",
      "\tFinal 0.5464681524216699 0.75371952727639\n",
      "======= fold 2 loss 0.75371952727639 ============\n",
      "\n",
      "\n",
      "============= Fold 3 ===========\n",
      "\t 0 1.2492635675632229 0.8936881888701315\n",
      "\t 10 0.7799398593944412 0.8241693705873789\n",
      "\t 20 0.7235722290124241 0.7933482353733734\n",
      "\t 30 0.6697933053902676 0.7723410037259685\n",
      "\t 40 0.6287872871407577 0.7608228385845908\n",
      "\t 50 0.6006014226986377 0.7551594895009263\n",
      "\t 60 0.5817025859540833 0.7529412431955143\n",
      "\t 70 0.5685972994337738 0.7516858449730692\n",
      "\t 80 0.5590187559244967 0.7512947635318404\n",
      "\t 90 0.55202091509235 0.7514702451712061\n",
      "\tFinal 0.5465233171792638 0.7515600060848673\n",
      "======= fold 3 loss 0.7515600060848673 ============\n",
      "\n",
      "\n",
      "============= Fold 4 ===========\n",
      "\t 0 1.2489322646078431 0.8901139973061846\n",
      "\t 10 0.7814179691981705 0.8265183882253605\n",
      "\t 20 0.7292955958754312 0.7995735983292912\n",
      "\t 30 0.6725178283082797 0.775798262365037\n",
      "\t 40 0.630519258323056 0.7620555451278721\n",
      "\t 50 0.6024541019923279 0.7554372593275449\n",
      "\t 60 0.5836898564309042 0.7521441242718241\n",
      "\t 70 0.5704069960267236 0.7508526278855064\n",
      "\t 80 0.5607084226759682 0.7500783305367481\n",
      "\t 90 0.553513426035628 0.7498696587409166\n",
      "\tFinal 0.5478169683213584 0.749699801930754\n",
      "======= fold 4 loss 0.749699801930754 ============\n",
      "\n",
      "\n",
      "============= Fold 5 ===========\n",
      "\t 0 1.2490041487546575 0.8929051175356411\n",
      "\t 10 0.7782381440270786 0.8254904603460482\n",
      "\t 20 0.7184302974484632 0.7937872502051138\n",
      "\t 30 0.6662040790897702 0.7733782360750112\n",
      "\t 40 0.6277971807705488 0.763338295848253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 50 0.6009716181301853 0.7580625474067376\n",
      "\t 60 0.582379256415953 0.7558669642638263\n",
      "\t 70 0.5692704228510136 0.7543656458231661\n",
      "\t 80 0.5596501254639026 0.7537558141946534\n",
      "\t 90 0.5524028808630612 0.7537394345606137\n",
      "\tFinal 0.5466941424695451 0.7537372173462676\n",
      "======= fold 5 loss 0.7537372173462676 ============\n",
      "\n",
      "\n",
      "==> 15,1,0.7519847069644519 == best (10,0.05,0.7495350542252549) =============\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "best_loss=1e10\n",
    "best_F=None\n",
    "steps=100\n",
    "if True:\n",
    "  for F in [5,10,15]: \n",
    "        print()\n",
    "        print(f\"F {F} :\")\n",
    "        model=Recommender(F,best_penalty,learning_rate,steps,batch_size)\n",
    "        loss=ratings_cross_validate(model,users,movies,ratings,\n",
    "                               folds)\n",
    "        results.append((F,loss))\n",
    "        if loss<best_loss:\n",
    "            best_loss=loss\n",
    "            best_F=F\n",
    "        print()\n",
    "        print(f\"==> {F},{penalty},{loss} == best ({best_F},{best_penalty},{best_loss}) =============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Best model\n",
    "\n",
    "Seems best model is really $F=10$ with penalty $0.02$, so we test performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T00:52:07.343377Z",
     "start_time": "2018-11-07T00:50:22.791082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 1.2487151147154587 0.8734996712312967\n",
      "\t 10 0.7854459353697039 0.8168954476243606\n",
      "\t 20 0.7298827082827767 0.7789219089035535\n",
      "\t 30 0.6857647008788721 0.7546617468115456\n",
      "\t 40 0.6565707493132016 0.7414681641613389\n",
      "\t 50 0.6377613938778485 0.7344088473281033\n",
      "\t 60 0.6254117611629383 0.7306500346148762\n",
      "\t 70 0.6170301391922364 0.7286495844998203\n",
      "\t 80 0.611048728955314 0.7274774636837298\n",
      "\t 90 0.606653455554716 0.7263877950958051\n",
      "\tFinal 0.6032863549775624 0.7261302778562422\n",
      "10 0.05 0.7261302778562422\n"
     ]
    }
   ],
   "source": [
    "model=Recommender(best_F,penalty_best,learning_rate,steps,batch_size)\n",
    "loss=model.fit(users,movies,ratings,users_test,movies_test,ratings_test)\n",
    "print(best_F,penalty_best,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T00:52:07.351286Z",
     "start_time": "2018-11-07T00:52:07.343377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7261302778562422"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved a $\\approx 0.73$ mean square error, a 12% improvement in accuracy over the 0.83 mean square error of the popularity model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
